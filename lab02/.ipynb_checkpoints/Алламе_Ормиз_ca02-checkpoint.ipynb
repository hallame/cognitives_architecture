{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "620jX06A4op6"
      },
      "source": [
        "# Лабораторная работа 2  \n",
        "## PPO + MuJoCo с фазовыми ограничениями на основе VLM\n",
        "\n",
        "В этой работе мы настраиваем среду MuJoCo `Reacher-v4`, обучаем агента с помощью PPO\n",
        "и добавляем фазовые ограничения, которые моделируют работу VLM из ДЗ1.\n",
        "Фазы определяются по расстоянию до цели, но функция оформлена так, чтобы её можно было\n",
        "заменить на настоящий VLM (по изображению и текстовым описаниям фаз).\n"
      ],
      "id": "620jX06A4op6"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"MUJOCO_GL\"] = \"egl\"\n"
      ],
      "metadata": {
        "id": "EVjx9kTdMcBq"
      },
      "id": "EVjx9kTdMcBq",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvqymK8j4op_"
      },
      "execution_count": 34,
      "outputs": [],
      "source": [
        "!pip install -q gymnasium[mujoco] mujoco stable-baselines3[extra] imageio[ffmpeg]\n"
      ],
      "id": "BvqymK8j4op_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjKNmwfH4oqB"
      },
      "execution_count": 35,
      "outputs": [],
      "source": [
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import HTML\n",
        "import imageio\n",
        "\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecMonitor\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n"
      ],
      "id": "yjKNmwfH4oqB"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5F34lNj4oqC"
      },
      "source": [
        "## 1. Создаём базовую среду MuJoCo (Reacher-v4)\n"
      ],
      "id": "h5F34lNj4oqC"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rh1P4yLH4oqD",
        "outputId": "a4e73d38-4b36-4e0a-f6c5-91fa36cc888f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observation space: Box(-inf, inf, (11,), float64)\n",
            "Action space: Box(-1.0, 1.0, (2,), float32)\n"
          ]
        }
      ],
      "source": [
        "ENV_ID = \"Reacher-v4\"\n",
        "\n",
        "def make_base_env(render_mode=None):\n",
        "    # Helper to create a single MuJoCo env instance.\n",
        "    env = gym.make(ENV_ID, render_mode=render_mode)\n",
        "    return env\n",
        "\n",
        "# Quick sanity check\n",
        "test_env = make_base_env(render_mode=None)\n",
        "print(\"Observation space:\", test_env.observation_space)\n",
        "print(\"Action space:\", test_env.action_space)\n",
        "test_env.close()\n"
      ],
      "id": "rh1P4yLH4oqD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O61z3WFO4oqE"
      },
      "source": [
        "## 2. Определяем фазы и VLM-подобный классификатор\n",
        "\n",
        "Мы считаем, что последняя часть вектора наблюдения Reacher-v4 хранит (target - fingertip),\n",
        "и по расстоянию между ними определяем фазу:\n",
        "- Phase 0: далеко от цели\n",
        "- Phase 1: рядом с целью\n",
        "- Phase 2: почти на цели (нужно стабилизироваться)\n"
      ],
      "id": "O61z3WFO4oqE"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOKGh3Jx4oqF"
      },
      "execution_count": 37,
      "outputs": [],
      "source": [
        "PHASE_DESCRIPTIONS = [\n",
        "    \"Phase 0: end-effector is far from the target\",\n",
        "    \"Phase 1: end-effector is near the target\",\n",
        "    \"Phase 2: end-effector is very close to the target and should stabilize\",\n",
        "]\n",
        "\n",
        "def estimate_distance_from_observation(obs: np.ndarray) -> float:\n",
        "    # Heuristic: in Reacher-v4, the last 2 dims approx. correspond to (target - fingertip).\n",
        "    if obs.shape[0] >= 2:\n",
        "        diff = obs[-2:]\n",
        "    else:\n",
        "        diff = obs\n",
        "    return float(np.linalg.norm(diff))\n",
        "\n",
        "def vlm_like_phase_classifier(obs: np.ndarray, phase_descriptions=None) -> int:\n",
        "    if phase_descriptions is None:\n",
        "        phase_descriptions = PHASE_DESCRIPTIONS\n",
        "\n",
        "    dist = estimate_distance_from_observation(obs)\n",
        "\n",
        "    # Thresholds for phases\n",
        "    if dist > 0.2:\n",
        "        phase_id = 0\n",
        "    elif dist > 0.05:\n",
        "        phase_id = 1\n",
        "    else:\n",
        "        phase_id = 2\n",
        "    return phase_id\n"
      ],
      "id": "aOKGh3Jx4oqF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVFsz9VR4oqG"
      },
      "source": [
        "## 3. Обёртка среды с фазовыми ограничениями\n",
        "\n",
        "Обёртка:\n",
        "- вычисляет фазу на каждом шаге,\n",
        "- даёт бонус при переходе в следующую фазу,\n",
        "- может штрафовать за откат (здесь 0, чтобы не усложнять).\n"
      ],
      "id": "cVFsz9VR4oqG"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHGLe0Zb4oqG"
      },
      "execution_count": 38,
      "outputs": [],
      "source": [
        "class PhaseConstraintWrapper(gym.Wrapper):\n",
        "    def __init__(self, env: gym.Env, phase_bonus: float = 1.0, backward_penalty: float = 0.0):\n",
        "        super().__init__(env)\n",
        "        self.phase_bonus = phase_bonus\n",
        "        self.backward_penalty = backward_penalty\n",
        "\n",
        "        self.phase_sequence = [0, 1, 2]\n",
        "        self.current_phase = 0\n",
        "        self.visited_phases = set()\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        obs, info = self.env.reset(**kwargs)\n",
        "        self.current_phase = 0\n",
        "        self.visited_phases = {0}\n",
        "        phase = vlm_like_phase_classifier(obs)\n",
        "        info = dict(info)\n",
        "        info[\"phase\"] = phase\n",
        "        info[\"current_phase\"] = self.current_phase\n",
        "        return obs, info\n",
        "\n",
        "    def step(self, action):\n",
        "        obs, reward, terminated, truncated, info = self.env.step(action)\n",
        "        info = dict(info)\n",
        "\n",
        "        phase = vlm_like_phase_classifier(obs)\n",
        "        shaped_reward = reward\n",
        "\n",
        "        # Progress to next phase\n",
        "        if phase > self.current_phase:\n",
        "            if phase == self.current_phase + 1:\n",
        "                self.current_phase = phase\n",
        "                if phase not in self.visited_phases:\n",
        "                    self.visited_phases.add(phase)\n",
        "                    shaped_reward += self.phase_bonus\n",
        "            else:\n",
        "                # Skip over phases: clip to next\n",
        "                self.current_phase += 1\n",
        "                if self.current_phase not in self.visited_phases:\n",
        "                    self.visited_phases.add(self.current_phase)\n",
        "                    shaped_reward += self.phase_bonus\n",
        "\n",
        "        #  penalty for going back\n",
        "        if phase < self.current_phase and self.backward_penalty > 0.0:\n",
        "            shaped_reward -= self.backward_penalty\n",
        "\n",
        "        info[\"phase\"] = phase\n",
        "        info[\"current_phase\"] = self.current_phase\n",
        "        info[\"visited_phases\"] = sorted(self.visited_phases)\n",
        "\n",
        "        return obs, shaped_reward, terminated, truncated, info\n"
      ],
      "id": "kHGLe0Zb4oqG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SO-Kzj7B4oqH"
      },
      "source": [
        "## 4. Векторизованная среда для PPO\n"
      ],
      "id": "SO-Kzj7B4oqH"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CJlLqzH4oqI"
      },
      "execution_count": 39,
      "outputs": [],
      "source": [
        "def make_training_env(seed: int = 0):\n",
        "    def _init():\n",
        "        env = make_base_env(render_mode=None)\n",
        "        env = PhaseConstraintWrapper(env, phase_bonus=1.0, backward_penalty=0.0)\n",
        "        env.reset(seed=seed)\n",
        "        return env\n",
        "    return _init\n",
        "\n",
        "num_envs = 4\n",
        "vec_env = DummyVecEnv([make_training_env(seed=i) for i in range(num_envs)])\n",
        "vec_env = VecMonitor(vec_env)\n"
      ],
      "id": "8CJlLqzH4oqI"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlyTlO8A4oqJ"
      },
      "source": [
        "## 5. Обучение агента PPO\n"
      ],
      "id": "YlyTlO8A4oqJ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yg348XAX4oqJ",
        "outputId": "237934f9-67c2-43dd-e463-88ef9ac3e841"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -59.4    |\n",
            "| time/              |          |\n",
            "|    fps             | 1670     |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 4        |\n",
            "|    total_timesteps | 8192     |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 50          |\n",
            "|    ep_rew_mean          | -57.2       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1035        |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 15          |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011836878 |\n",
            "|    clip_fraction        | 0.0583      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.75       |\n",
            "|    explained_variance   | 0.00894     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 12.4        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00669    |\n",
            "|    std                  | 0.935       |\n",
            "|    value_loss           | 78.2        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 50          |\n",
            "|    ep_rew_mean          | -54.3       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 942         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 26          |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009523982 |\n",
            "|    clip_fraction        | 0.0873      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.63       |\n",
            "|    explained_variance   | 0.396       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.47        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.00908    |\n",
            "|    std                  | 0.892       |\n",
            "|    value_loss           | 24          |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 50         |\n",
            "|    ep_rew_mean          | -51.6      |\n",
            "| time/                   |            |\n",
            "|    fps                  | 924        |\n",
            "|    iterations           | 4          |\n",
            "|    time_elapsed         | 35         |\n",
            "|    total_timesteps      | 32768      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01545614 |\n",
            "|    clip_fraction        | 0.116      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.51      |\n",
            "|    explained_variance   | 0.512      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 6.54       |\n",
            "|    n_updates            | 30         |\n",
            "|    policy_gradient_loss | -0.0131    |\n",
            "|    std                  | 0.833      |\n",
            "|    value_loss           | 15.7       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 50          |\n",
            "|    ep_rew_mean          | -48.7       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 919         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 44          |\n",
            "|    total_timesteps      | 40960       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019043304 |\n",
            "|    clip_fraction        | 0.147       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.37       |\n",
            "|    explained_variance   | 0.567       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.71        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0178     |\n",
            "|    std                  | 0.772       |\n",
            "|    value_loss           | 11.7        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 50          |\n",
            "|    ep_rew_mean          | -47.6       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 908         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 54          |\n",
            "|    total_timesteps      | 49152       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019338477 |\n",
            "|    clip_fraction        | 0.159       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.21       |\n",
            "|    explained_variance   | 0.698       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.43        |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0199     |\n",
            "|    std                  | 0.718       |\n",
            "|    value_loss           | 8.3         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 50          |\n",
            "|    ep_rew_mean          | -45.3       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 902         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 63          |\n",
            "|    total_timesteps      | 57344       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021335712 |\n",
            "|    clip_fraction        | 0.192       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.05       |\n",
            "|    explained_variance   | 0.79        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.95        |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.0249     |\n",
            "|    std                  | 0.659       |\n",
            "|    value_loss           | 6.19        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 50          |\n",
            "|    ep_rew_mean          | -43.6       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 897         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 72          |\n",
            "|    total_timesteps      | 65536       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023895882 |\n",
            "|    clip_fraction        | 0.216       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.87       |\n",
            "|    explained_variance   | 0.859       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.79        |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.0269     |\n",
            "|    std                  | 0.607       |\n",
            "|    value_loss           | 4.27        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 50          |\n",
            "|    ep_rew_mean          | -42.6       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 894         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 82          |\n",
            "|    total_timesteps      | 73728       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.025477188 |\n",
            "|    clip_fraction        | 0.202       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.7        |\n",
            "|    explained_variance   | 0.901       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.14        |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.0247     |\n",
            "|    std                  | 0.555       |\n",
            "|    value_loss           | 3.34        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 50         |\n",
            "|    ep_rew_mean          | -40.2      |\n",
            "| time/                   |            |\n",
            "|    fps                  | 896        |\n",
            "|    iterations           | 10         |\n",
            "|    time_elapsed         | 91         |\n",
            "|    total_timesteps      | 81920      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02603957 |\n",
            "|    clip_fraction        | 0.219      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.51      |\n",
            "|    explained_variance   | 0.921      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.862      |\n",
            "|    n_updates            | 90         |\n",
            "|    policy_gradient_loss | -0.0247    |\n",
            "|    std                  | 0.51       |\n",
            "|    value_loss           | 2.24       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 50          |\n",
            "|    ep_rew_mean          | -39.5       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 894         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 100         |\n",
            "|    total_timesteps      | 90112       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.026648391 |\n",
            "|    clip_fraction        | 0.223       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.33       |\n",
            "|    explained_variance   | 0.939       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.729       |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.0226     |\n",
            "|    std                  | 0.465       |\n",
            "|    value_loss           | 1.5         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 50          |\n",
            "|    ep_rew_mean          | -36.9       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 891         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 110         |\n",
            "|    total_timesteps      | 98304       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023316832 |\n",
            "|    clip_fraction        | 0.205       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.15       |\n",
            "|    explained_variance   | 0.948       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.552       |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.0223     |\n",
            "|    std                  | 0.425       |\n",
            "|    value_loss           | 1.2         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 50          |\n",
            "|    ep_rew_mean          | -35         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 889         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 119         |\n",
            "|    total_timesteps      | 106496      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024056409 |\n",
            "|    clip_fraction        | 0.199       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.975      |\n",
            "|    explained_variance   | 0.951       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.52        |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.0217     |\n",
            "|    std                  | 0.389       |\n",
            "|    value_loss           | 1.06        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 50          |\n",
            "|    ep_rew_mean          | -31.5       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 888         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 129         |\n",
            "|    total_timesteps      | 114688      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023299834 |\n",
            "|    clip_fraction        | 0.203       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.797      |\n",
            "|    explained_variance   | 0.946       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.315       |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.0197     |\n",
            "|    std                  | 0.356       |\n",
            "|    value_loss           | 0.897       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 50          |\n",
            "|    ep_rew_mean          | -27.7       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 890         |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 138         |\n",
            "|    total_timesteps      | 122880      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021755567 |\n",
            "|    clip_fraction        | 0.213       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.631      |\n",
            "|    explained_variance   | 0.929       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.42        |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.0187     |\n",
            "|    std                  | 0.329       |\n",
            "|    value_loss           | 0.814       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 50          |\n",
            "|    ep_rew_mean          | -25.2       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 888         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 147         |\n",
            "|    total_timesteps      | 131072      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023175254 |\n",
            "|    clip_fraction        | 0.234       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.468      |\n",
            "|    explained_variance   | 0.88        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.258       |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.02       |\n",
            "|    std                  | 0.303       |\n",
            "|    value_loss           | 0.708       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 50         |\n",
            "|    ep_rew_mean          | -21.4      |\n",
            "| time/                   |            |\n",
            "|    fps                  | 887        |\n",
            "|    iterations           | 17         |\n",
            "|    time_elapsed         | 156        |\n",
            "|    total_timesteps      | 139264     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02135601 |\n",
            "|    clip_fraction        | 0.212      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.337     |\n",
            "|    explained_variance   | 0.815      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.307      |\n",
            "|    n_updates            | 160        |\n",
            "|    policy_gradient_loss | -0.0194    |\n",
            "|    std                  | 0.283      |\n",
            "|    value_loss           | 0.694      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 50          |\n",
            "|    ep_rew_mean          | -19.1       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 881         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 167         |\n",
            "|    total_timesteps      | 147456      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021163944 |\n",
            "|    clip_fraction        | 0.224       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.202      |\n",
            "|    explained_variance   | 0.668       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.27        |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.0188     |\n",
            "|    std                  | 0.265       |\n",
            "|    value_loss           | 0.642       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 50         |\n",
            "|    ep_rew_mean          | -17.3      |\n",
            "| time/                   |            |\n",
            "|    fps                  | 877        |\n",
            "|    iterations           | 19         |\n",
            "|    time_elapsed         | 177        |\n",
            "|    total_timesteps      | 155648     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02237712 |\n",
            "|    clip_fraction        | 0.208      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.075     |\n",
            "|    explained_variance   | 0.559      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.346      |\n",
            "|    n_updates            | 180        |\n",
            "|    policy_gradient_loss | -0.0188    |\n",
            "|    std                  | 0.248      |\n",
            "|    value_loss           | 0.734      |\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.ppo.ppo.PPO at 0x7da382a143b0>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "total_timesteps = 150_000\n",
        "\n",
        "model = PPO(\n",
        "    policy=\"MlpPolicy\",\n",
        "    env=vec_env,\n",
        "    n_steps=2048,\n",
        "    batch_size=64,\n",
        "    gae_lambda=0.95,\n",
        "    gamma=0.99,\n",
        "    learning_rate=3e-4,\n",
        "    clip_range=0.2,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "model.learn(total_timesteps=total_timesteps)\n"
      ],
      "id": "Yg348XAX4oqJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md48LAZ34oqK"
      },
      "source": [
        "## 6. Оценка политики\n"
      ],
      "id": "md48LAZ34oqK"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5K5_Vpfm4oqK",
        "outputId": "b324961e-e094-417d-cc46-25cdc9b0d5df"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean reward over 10 episodes: -8.17 ± 1.61\n"
          ]
        }
      ],
      "source": [
        "eval_env = DummyVecEnv([make_training_env(seed=123)])\n",
        "mean_reward, std_reward = evaluate_policy(\n",
        "    model,\n",
        "    eval_env,\n",
        "    n_eval_episodes=10,\n",
        "    deterministic=True\n",
        ")\n",
        "print(f\"Mean reward over 10 episodes: {mean_reward:.2f} ± {std_reward:.2f}\")\n"
      ],
      "id": "5K5_Vpfm4oqK"
    },
    {
      "cell_type": "code",
      "source": [
        "# from stable_baselines3.common.monitor import Monitor\n",
        "\n",
        "# def make_eval_env(seed: int = 123):\n",
        "#     def _init():\n",
        "#         env = make_base_env(render_mode=None)\n",
        "#         env = PhaseConstraintWrapper(env, phase_bonus=1.0, backward_penalty=0.0)\n",
        "#         env = Monitor(env)\n",
        "#         env.reset(seed=seed)\n",
        "#         return env\n",
        "#     return _init\n",
        "\n",
        "# eval_env = DummyVecEnv([make_eval_env(seed=123)])\n",
        "# mean_reward, std_reward = evaluate_policy(\n",
        "#     model, eval_env, n_eval_episodes=10, deterministic=True\n",
        "# )\n",
        "# print(f\"Mean reward over 10 episodes: {mean_reward:.2f} ± {std_reward:.2f}\")\n"
      ],
      "metadata": {
        "id": "-avZbKcvLNNC"
      },
      "id": "-avZbKcvLNNC",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHrg0bYk4oqL"
      },
      "source": [
        "## 7. Запись видео эпизода с фазами\n"
      ],
      "id": "rHrg0bYk4oqL"
    },
    {
      "cell_type": "code",
      "source": [
        "def run_episode_with_phases(model, max_steps=300):\n",
        "    # Pas de render_mode=\"rgb_array\" pour éviter OpenGL\n",
        "    env = make_base_env(render_mode=None)\n",
        "    env = PhaseConstraintWrapper(env, phase_bonus=1.0, backward_penalty=0.0)\n",
        "    obs, info = env.reset()\n",
        "    phases = []\n",
        "    total_reward = 0.0\n",
        "\n",
        "    for step in range(max_steps):\n",
        "        action, _ = model.predict(obs, deterministic=True)\n",
        "        obs, reward, terminated, truncated, info = env.step(action)\n",
        "        total_reward += reward\n",
        "\n",
        "        phases.append(info.get(\"current_phase\", 0))\n",
        "\n",
        "        if terminated or truncated:\n",
        "            break\n",
        "\n",
        "    env.close()\n",
        "    print(f\"Episode reward (no rendering): {total_reward:.2f}\")\n",
        "    return phases\n",
        "\n",
        "phases = run_episode_with_phases(model, max_steps=300)\n",
        "\n",
        "plt.figure(figsize=(6, 3))\n",
        "plt.plot(phases, marker=\"o\")\n",
        "plt.yticks([0, 1, 2])\n",
        "plt.xlabel(\"Step\")\n",
        "plt.ylabel(\"Phase\")\n",
        "plt.title(\"Phase progression during evaluation episode\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "4kkPb6gPOWRG",
        "outputId": "dc324edb-3593-4831-da97-c7f695e2f7ee"
      },
      "id": "4kkPb6gPOWRG",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode reward (no rendering): -11.02\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "NDsl1-DZ4oqL",
        "outputId": "a791ae55-4199-4b6d-b8d1-58a6547fa043"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FatalError",
          "evalue": "gladLoadGL error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFatalError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1933686516.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mphases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mphases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord_episode_with_phases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ppo_reacher_phases.mp4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1933686516.py\u001b[0m in \u001b[0;36mrecord_episode_with_phases\u001b[0;34m(model, max_steps, fps, video_path)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mRenderFrame\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mRenderFrame\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;34m\"\"\"Uses the :meth:`render` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mRenderFrame\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mRenderFrame\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;34m\"\"\"Uses the :meth:`render` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/wrappers/common.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;34m\"set `disable_render_order_enforcing=True` on the OrderEnforcer wrapper.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             )\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mRenderFrame\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mRenderFrame\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;34m\"\"\"Uses the :meth:`render` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/wrappers/common.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchecked_render\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchecked_render\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0menv_render_passive_checker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/utils/passive_env_checker.py\u001b[0m in \u001b[0;36menv_render_passive_checker\u001b[0;34m(env)\u001b[0m\n\u001b[1;32m    359\u001b[0m             )\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender_mode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0m_check_render_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/envs/mujoco/mujoco_env.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mRender\u001b[0m \u001b[0ma\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMuJoCo\u001b[0m \u001b[0msimulation\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mspecified\u001b[0m \u001b[0mby\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mrender_mode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \"\"\"\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmujoco_renderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/envs/mujoco/mujoco_rendering.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, render_mode)\u001b[0m\n\u001b[1;32m    760\u001b[0m             ), f\"The width: {self.width} and height: {self.height} cannot be `None` when the render_mode is not `human`.\"\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_viewer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrender_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrender_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrender_mode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"rgb_array\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"depth_array\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rgbd_tuple\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/envs/mujoco/mujoco_rendering.py\u001b[0m in \u001b[0;36m_get_viewer\u001b[0;34m(self, render_mode)\u001b[0m\n\u001b[1;32m    784\u001b[0m                 )\n\u001b[1;32m    785\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mrender_mode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"rgb_array\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"depth_array\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rgbd_tuple\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m                 self.viewer = OffScreenViewer(\n\u001b[0m\u001b[1;32m    787\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/envs/mujoco/mujoco_rendering.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, data, width, height, max_geom, visual_options)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_opengl_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_geom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisual_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_camera\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/envs/mujoco/mujoco_rendering.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, data, width, height, max_geom, visual_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# Keep in Mujoco Context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmujoco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMjrContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmujoco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmjtFontScale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmjFONTSCALE_150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mujoco_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFatalError\u001b[0m: gladLoadGL error"
          ]
        }
      ],
      "source": [
        "def record_episode_with_phases(model, max_steps=300, fps=30, video_path=\"ppo_reacher_phases.mp4\"):\n",
        "    env = make_base_env(render_mode=\"rgb_array\")\n",
        "    env = PhaseConstraintWrapper(env, phase_bonus=1.0, backward_penalty=0.0)\n",
        "    obs, info = env.reset()\n",
        "    frames = []\n",
        "    phases = []\n",
        "    total_reward = 0.0\n",
        "\n",
        "    for step in range(max_steps):\n",
        "        frame = env.render()\n",
        "        if frame is not None:\n",
        "            frames.append(frame)\n",
        "\n",
        "        action, _ = model.predict(obs, deterministic=True)\n",
        "        obs, reward, terminated, truncated, info = env.step(action)\n",
        "        total_reward += reward\n",
        "        phases.append(info.get(\"current_phase\", 0))\n",
        "\n",
        "        if terminated or truncated:\n",
        "            break\n",
        "\n",
        "    env.close()\n",
        "\n",
        "    if frames:\n",
        "        imageio.mimsave(video_path, frames, fps=fps)\n",
        "        print(f\"Saved video to {video_path}, episode reward = {total_reward:.2f}\")\n",
        "    else:\n",
        "        print(\"No frames recorded (render_mode might not be supported).\")\n",
        "\n",
        "    return phases\n",
        "\n",
        "phases = record_episode_with_phases(model, max_steps=300, fps=30, video_path=\"ppo_reacher_phases.mp4\")\n",
        "\n",
        "plt.figure(figsize=(6, 3))\n",
        "plt.plot(phases, marker=\"o\")\n",
        "plt.yticks([0, 1, 2])\n",
        "plt.xlabel(\"Step\")\n",
        "plt.ylabel(\"Phase\")\n",
        "plt.title(\"Phase progression during evaluation episode\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "HTML(\"\"\"\n",
        "<video width=\"480\" controls>\n",
        "<source src=\"ppo_reacher_phases.mp4\" type=\"video/mp4\">\n",
        "Your browser does not support the video tag.\n",
        "</video>\"\"\")\n"
      ],
      "id": "NDsl1-DZ4oqL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATgJ2JQ_4oqM"
      },
      "source": [
        "## 8. Вывод\n",
        "\n",
        "Мы настроили обучение агента PPO в среде MuJoCo `Reacher-v4` и добавили фазовые ограничения,\n",
        "имитируя работу VLM:\n",
        "- фазы определяются по расстоянию до цели,\n",
        "- обёртка `PhaseConstraintWrapper` даёт бонусы при переходе в новую фазу,\n",
        "- получившуюся архитектуру легко расширить, подставив настоящую VLM-модель вместо функции\n",
        "`vlm_like_phase_classifier` и используя текстовые описания фаз из постановки задачи.\n"
      ],
      "id": "ATgJ2JQ_4oqM"
    }
  ]
}