{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "620jX06A4op6",
   "metadata": {
    "id": "620jX06A4op6"
   },
   "source": [
    "# Лабораторная работа 2  \n",
    "## PPO + MuJoCo с фазовыми ограничениями на основе VLM\n",
    "\n",
    "В этой работе мы настраиваем среду MuJoCo `Reacher-v4`, обучаем агента с помощью PPO\n",
    "и добавляем фазовые ограничения, которые моделируют работу VLM из ДЗ1.\n",
    "Фазы определяются по расстоянию до цели, но функция оформлена так, чтобы её можно было\n",
    "заменить на настоящий VLM (по изображению и текстовым описаниям фаз).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "yjKNmwfH4oqB",
   "metadata": {
    "id": "yjKNmwfH4oqB"
   },
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "import imageio\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecMonitor\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h5F34lNj4oqC",
   "metadata": {
    "id": "h5F34lNj4oqC"
   },
   "source": [
    "## 1. Создаём базовую среду MuJoCo (Reacher-v4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rh1P4yLH4oqD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rh1P4yLH4oqD",
    "outputId": "a4e73d38-4b36-4e0a-f6c5-91fa36cc888f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space: Box(-inf, inf, (11,), float64)\n",
      "Action space: Box(-1.0, 1.0, (2,), float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hormi\\OneDrive\\Bureau\\CognArchit\\lab02\\.venv\\Lib\\site-packages\\gymnasium\\envs\\registration.py:512: DeprecationWarning: \u001b[33mWARN: The environment Reacher-v4 is out of date. You should consider upgrading to version `v5`.\u001b[0m\n",
      "  logger.deprecation(\n"
     ]
    }
   ],
   "source": [
    "ENV_ID = \"Reacher-v4\"\n",
    "\n",
    "def make_base_env(render_mode=None):\n",
    "    # Helper to create a single MuJoCo env instance.\n",
    "    env = gym.make(ENV_ID, render_mode=render_mode)\n",
    "    return env\n",
    "\n",
    "# Quick sanity check\n",
    "test_env = make_base_env(render_mode=None)\n",
    "print(\"Observation space:\", test_env.observation_space)\n",
    "print(\"Action space:\", test_env.action_space)\n",
    "test_env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "O61z3WFO4oqE",
   "metadata": {
    "id": "O61z3WFO4oqE"
   },
   "source": [
    "## 2. Определяем фазы и VLM-подобный классификатор\n",
    "\n",
    "Мы считаем, что последняя часть вектора наблюдения Reacher-v4 хранит (target - fingertip),\n",
    "и по расстоянию между ними определяем фазу:\n",
    "- Phase 0: далеко от цели\n",
    "- Phase 1: рядом с целью\n",
    "- Phase 2: почти на цели (нужно стабилизироваться)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aOKGh3Jx4oqF",
   "metadata": {
    "id": "aOKGh3Jx4oqF"
   },
   "outputs": [],
   "source": [
    "PHASE_DESCRIPTIONS = [\n",
    "    \"Phase 0: end-effector is far from the target\",\n",
    "    \"Phase 1: end-effector is near the target\",\n",
    "    \"Phase 2: end-effector is very close to the target and should stabilize\",\n",
    "]\n",
    "\n",
    "def estimate_distance_from_observation(obs: np.ndarray) -> float:\n",
    "    # Heuristic: in Reacher-v4, the last 2 dims approx. correspond to (target - fingertip).\n",
    "    if obs.shape[0] >= 2:\n",
    "        diff = obs[-2:]\n",
    "    else:\n",
    "        diff = obs\n",
    "    return float(np.linalg.norm(diff))\n",
    "\n",
    "def vlm_like_phase_classifier(obs: np.ndarray, phase_descriptions=None) -> int:\n",
    "    if phase_descriptions is None:\n",
    "        phase_descriptions = PHASE_DESCRIPTIONS\n",
    "\n",
    "    dist = estimate_distance_from_observation(obs)\n",
    "\n",
    "    # Thresholds for phases\n",
    "    if dist > 0.2:\n",
    "        phase_id = 0\n",
    "    elif dist > 0.05:\n",
    "        phase_id = 1\n",
    "    else:\n",
    "        phase_id = 2\n",
    "    return phase_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cVFsz9VR4oqG",
   "metadata": {
    "id": "cVFsz9VR4oqG"
   },
   "source": [
    "## 3. Обёртка среды с фазовыми ограничениями\n",
    "\n",
    "Обёртка:\n",
    "- вычисляет фазу на каждом шаге,\n",
    "- даёт бонус при переходе в следующую фазу,\n",
    "- может штрафовать за откат (здесь 0, чтобы не усложнять).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "kHGLe0Zb4oqG",
   "metadata": {
    "id": "kHGLe0Zb4oqG"
   },
   "outputs": [],
   "source": [
    "class PhaseConstraintWrapper(gym.Wrapper):\n",
    "    def __init__(self, env: gym.Env, phase_bonus: float = 1.0, backward_penalty: float = 0.0):\n",
    "        super().__init__(env)\n",
    "        self.phase_bonus = phase_bonus\n",
    "        self.backward_penalty = backward_penalty\n",
    "\n",
    "        self.phase_sequence = [0, 1, 2]\n",
    "        self.current_phase = 0\n",
    "        self.visited_phases = set()\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        obs, info = self.env.reset(**kwargs)\n",
    "        self.current_phase = 0\n",
    "        self.visited_phases = {0}\n",
    "        phase = vlm_like_phase_classifier(obs)\n",
    "        info = dict(info)\n",
    "        info[\"phase\"] = phase\n",
    "        info[\"current_phase\"] = self.current_phase\n",
    "        return obs, info\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "        info = dict(info)\n",
    "\n",
    "        phase = vlm_like_phase_classifier(obs)\n",
    "        shaped_reward = reward\n",
    "\n",
    "        # Progress to next phase\n",
    "        if phase > self.current_phase:\n",
    "            if phase == self.current_phase + 1:\n",
    "                self.current_phase = phase\n",
    "                if phase not in self.visited_phases:\n",
    "                    self.visited_phases.add(phase)\n",
    "                    shaped_reward += self.phase_bonus\n",
    "            else:\n",
    "                # Skip over phases: clip to next\n",
    "                self.current_phase += 1\n",
    "                if self.current_phase not in self.visited_phases:\n",
    "                    self.visited_phases.add(self.current_phase)\n",
    "                    shaped_reward += self.phase_bonus\n",
    "\n",
    "        #  penalty for going back\n",
    "        if phase < self.current_phase and self.backward_penalty > 0.0:\n",
    "            shaped_reward -= self.backward_penalty\n",
    "\n",
    "        info[\"phase\"] = phase\n",
    "        info[\"current_phase\"] = self.current_phase\n",
    "        info[\"visited_phases\"] = sorted(self.visited_phases)\n",
    "\n",
    "        return obs, shaped_reward, terminated, truncated, info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SO-Kzj7B4oqH",
   "metadata": {
    "id": "SO-Kzj7B4oqH"
   },
   "source": [
    "## 4. Векторизованная среда для PPO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8CJlLqzH4oqI",
   "metadata": {
    "id": "8CJlLqzH4oqI"
   },
   "outputs": [],
   "source": [
    "def make_training_env(seed: int = 0):\n",
    "    def _init():\n",
    "        env = make_base_env(render_mode=None)\n",
    "        env = PhaseConstraintWrapper(env, phase_bonus=1.0, backward_penalty=0.0)\n",
    "        env.reset(seed=seed)\n",
    "        return env\n",
    "    return _init\n",
    "\n",
    "num_envs = 4\n",
    "vec_env = DummyVecEnv([make_training_env(seed=i) for i in range(num_envs)])\n",
    "vec_env = VecMonitor(vec_env)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YlyTlO8A4oqJ",
   "metadata": {
    "id": "YlyTlO8A4oqJ"
   },
   "source": [
    "## 5. Обучение агента PPO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "Yg348XAX4oqJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yg348XAX4oqJ",
    "outputId": "237934f9-67c2-43dd-e463-88ef9ac3e841"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -59.4    |\n",
      "| time/              |          |\n",
      "|    fps             | 2580     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -56.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1274        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011284793 |\n",
      "|    clip_fraction        | 0.058       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.76       |\n",
      "|    explained_variance   | -0.00512    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00654    |\n",
      "|    std                  | 0.938       |\n",
      "|    value_loss           | 79.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -53.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1094        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012679923 |\n",
      "|    clip_fraction        | 0.0903      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.62       |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.9         |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00932    |\n",
      "|    std                  | 0.879       |\n",
      "|    value_loss           | 23.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -51.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1029        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014940487 |\n",
      "|    clip_fraction        | 0.0932      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.48       |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.61        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00979    |\n",
      "|    std                  | 0.819       |\n",
      "|    value_loss           | 16          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -47.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1040        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018495077 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.33       |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.92        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    std                  | 0.758       |\n",
      "|    value_loss           | 11.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -46         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1065        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019102778 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.17       |\n",
      "|    explained_variance   | 0.635       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.99        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    std                  | 0.702       |\n",
      "|    value_loss           | 7.9         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -44         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1088        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022101186 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.02       |\n",
      "|    explained_variance   | 0.813       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.98        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    std                  | 0.65        |\n",
      "|    value_loss           | 6.6         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -41.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1106        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022636522 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | 0.856       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.22        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    std                  | 0.597       |\n",
      "|    value_loss           | 5.07        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -42         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1120        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024840916 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | 0.889       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.88        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    std                  | 0.552       |\n",
      "|    value_loss           | 3.62        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -39.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1129        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022839762 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | 0.919       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.28        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0262     |\n",
      "|    std                  | 0.51        |\n",
      "|    value_loss           | 3.25        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -39.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1137        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 79          |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022878632 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.936       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.25        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.023      |\n",
      "|    std                  | 0.469       |\n",
      "|    value_loss           | 2.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -40.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1129        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023794608 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.759       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    std                  | 0.431       |\n",
      "|    value_loss           | 1.59        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -38.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1122        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020505492 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.408       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 0.397       |\n",
      "|    value_loss           | 1.14        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -36.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1132        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020562392 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.873      |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.627       |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 0.368       |\n",
      "|    value_loss           | 1.04        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -35.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1145        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021516591 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.703      |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.467       |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    std                  | 0.338       |\n",
      "|    value_loss           | 0.909       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -32.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1151        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019724123 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.546      |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.355       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 0.314       |\n",
      "|    value_loss           | 0.724       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -29.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1155        |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 120         |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027668998 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.393      |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.286       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    std                  | 0.291       |\n",
      "|    value_loss           | 0.651       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -26.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1160        |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 127         |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020899195 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.25       |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.241       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    std                  | 0.27        |\n",
      "|    value_loss           | 0.565       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 50         |\n",
      "|    ep_rew_mean          | -23.1      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1163       |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 133        |\n",
      "|    total_timesteps      | 155648     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02053716 |\n",
      "|    clip_fraction        | 0.2        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.106     |\n",
      "|    explained_variance   | 0.932      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.209      |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.0159    |\n",
      "|    std                  | 0.253      |\n",
      "|    value_loss           | 0.515      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1f1fad42f90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_timesteps = 150_000\n",
    "\n",
    "model = PPO(\n",
    "    policy=\"MlpPolicy\",\n",
    "    env=vec_env,\n",
    "    n_steps=2048,\n",
    "    batch_size=64,\n",
    "    gae_lambda=0.95,\n",
    "    gamma=0.99,\n",
    "    learning_rate=3e-4,\n",
    "    clip_range=0.2,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "model.learn(total_timesteps=total_timesteps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md48LAZ34oqK",
   "metadata": {
    "id": "md48LAZ34oqK"
   },
   "source": [
    "## 6. Оценка политики\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5K5_Vpfm4oqK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5K5_Vpfm4oqK",
    "outputId": "b324961e-e094-417d-cc46-25cdc9b0d5df"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hormi\\OneDrive\\Bureau\\CognArchit\\lab02\\.venv\\Lib\\site-packages\\gymnasium\\envs\\registration.py:512: DeprecationWarning: \u001b[33mWARN: The environment Reacher-v4 is out of date. You should consider upgrading to version `v5`.\u001b[0m\n",
      "  logger.deprecation(\n",
      "c:\\Users\\hormi\\OneDrive\\Bureau\\CognArchit\\lab02\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\evaluation.py:70: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward over 10 episodes: -13.68 ± 1.44\n"
     ]
    }
   ],
   "source": [
    "eval_env = DummyVecEnv([make_training_env(seed=123)])\n",
    "mean_reward, std_reward = evaluate_policy(\n",
    "    model,\n",
    "    eval_env,\n",
    "    n_eval_episodes=10,\n",
    "    deterministic=True\n",
    ")\n",
    "print(f\"Mean reward over 10 episodes: {mean_reward:.2f} ± {std_reward:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rHrg0bYk4oqL",
   "metadata": {
    "id": "rHrg0bYk4oqL"
   },
   "source": [
    "## 7. Запись видео эпизода с фазами\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "NDsl1-DZ4oqL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "id": "NDsl1-DZ4oqL",
    "outputId": "a791ae55-4199-4b6d-b8d1-58a6547fa043"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved video to ppo_reacher_phases.mp4, episode reward = -14.50\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"480\" controls>\n",
       "<source src=\"ppo_reacher_phases.mp4\" type=\"video/mp4\">\n",
       "Your browser does not support the video tag.\n",
       "</video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def record_episode_with_phases(model, max_steps=300, fps=30, video_path=\"ppo_reacher_phases.mp4\"):\n",
    "    env = make_base_env(render_mode=\"rgb_array\")\n",
    "    env = PhaseConstraintWrapper(env, phase_bonus=1.0, backward_penalty=0.0)\n",
    "    obs, info = env.reset()\n",
    "    frames = []\n",
    "    phases = []\n",
    "    total_reward = 0.0\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        frame = env.render()\n",
    "        if frame is not None:\n",
    "            frames.append(frame)\n",
    "\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        phases.append(info.get(\"current_phase\", 0))\n",
    "\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    if frames:\n",
    "        imageio.mimsave(video_path, frames, fps=fps)\n",
    "        print(f\"Saved video to {video_path}, episode reward = {total_reward:.2f}\")\n",
    "    else:\n",
    "        print(\"No frames recorded (render_mode might not be supported).\")\n",
    "\n",
    "    return phases\n",
    "\n",
    "phases = record_episode_with_phases(model, max_steps=300, fps=30, video_path=\"ppo_reacher_phases.mp4\")\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.plot(phases, marker=\"o\")\n",
    "plt.yticks([0, 1, 2])\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Phase\")\n",
    "plt.title(\"Phase progression during evaluation episode\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"480\" controls>\n",
    "<source src=\"ppo_reacher_phases.mp4\" type=\"video/mp4\">\n",
    "Your browser does not support the video tag.\n",
    "</video>\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
